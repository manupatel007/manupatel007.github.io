<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <title>Computer Vision</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"> </script>
<script>
  class Webcam {
  /**
   * @param {HTMLVideoElement} webcamElement A HTMLVideoElement representing the
   *     webcam feed.
   */
  constructor(webcamElement) {
    this.webcamElement = webcamElement;
  }

  /**
   * Captures a frame from the webcam and normalizes it between -1 and 1.
   * Returns a batched image (1-element batch) of shape [1, w, h, c].
   */


  capture() {
    return tf.tidy(() => {
      // Reads the image as a Tensor from the webcam <video> element.
      const webcamImage = tf.browser.fromPixels(this.webcamElement);

      const reversedImage = webcamImage.reverse(1);

      // Crop the image so we're using the center square of the rectangular
      // webcam.
      const croppedImage = this.cropImage(reversedImage);

      // Expand the outer most dimension so we have a batch size of 1.
      const batchedImage = croppedImage.expandDims(0);

      // Normalize the image between -1 and 1. The image comes in between 0-255,
      // so we divide by 127 and subtract 1.
      return batchedImage.toFloat().div(tf.scalar(127)).sub(tf.scalar(1));
    });
  }

  /**
   * Crops an image tensor so we get a square image with no white space.
   * @param {Tensor4D} img An input image Tensor to crop.
   */


  cropImage(img) {
    const size = Math.min(img.shape[0], img.shape[1]);
    const centerHeight = img.shape[0] / 2;
    const beginHeight = centerHeight - (size / 2);
    const centerWidth = img.shape[1] / 2;
    const beginWidth = centerWidth - (size / 2);
    return img.slice([beginHeight, beginWidth, 0], [size, size, 3]);
  }

  /**
   * Adjusts the video size so we can make a centered square crop without
   * including whitespace.
   * @param {number} width The real width of the video element.
   * @param {number} height The real height of the video element.
   */


  adjustVideoSize(width, height) {
    const aspectRatio = width / height;
    if (width >= height) {
      this.webcamElement.width = aspectRatio * this.webcamElement.height;
    } else if (width < height) {
      this.webcamElement.height = this.webcamElement.width / aspectRatio;
    }
  }

  async setup() {
    return new Promise((resolve, reject) => {
      navigator.getUserMedia = navigator.getUserMedia ||
          navigator.webkitGetUserMedia || navigator.mozGetUserMedia ||
          navigator.msGetUserMedia;
      if (navigator.getUserMedia) {
        navigator.getUserMedia(
            {video: {width: 224, height: 224}},
            stream => {
              this.webcamElement.srcObject = stream;
              this.webcamElement.addEventListener('loadeddata', async () => {
                this.adjustVideoSize(
                    this.webcamElement.videoWidth,
                    this.webcamElement.videoHeight);
                resolve();
              }, false);
            },
            error => {
              reject(error);
            });
      } else {
        reject();
      }
    });
  }
} 
</script>
<script>
  class RPSDataset {
  constructor() {
    this.labels = []
  }

  addExample(example, label) {
    if (this.xs == null) {
      this.xs = tf.keep(example);
      this.labels.push(label);
    } else {
      const oldX = this.xs;
      this.xs = tf.keep(oldX.concat(example, 0));
      this.labels.push(label);
      oldX.dispose();
    }
  }
  
  encodeLabels(numClasses) {
    for (var i = 0; i < this.labels.length; i++) {
      if (this.ys == null) {
        this.ys = tf.keep(tf.tidy(
            () => {return tf.oneHot(
                tf.tensor1d([this.labels[i]]).toInt(), numClasses)}));
      } else {
        const y = tf.tidy(
            () => {return tf.oneHot(
                tf.tensor1d([this.labels[i]]).toInt(), numClasses)});
        const oldY = this.ys;
        this.ys = tf.keep(oldY.concat(y, 0));
        oldY.dispose();
        y.dispose();
      }
    }
  }
}    
</script>
<script>
  var cnt=1;
    function Createbtn() {
        
    cnt++;
        // NOW CREATE AN INPUT BOX TYPE BUTTON USING createElement() METHOD.
        var button = document.createElement('input');

        // SET INPUT ATTRIBUTE 'type' AND 'value'.
        button.setAttribute('type', 'button');
        button.setAttribute('value', 'Class '+cnt);
  button.setAttribute('id', cnt);
        // ADD THE BUTTON's 'onclick' EVENT.
        button.setAttribute('onclick', 'handleButton(this)');
  
  var elementAbove = document.getElementById("yes");

  var line = document.createElement('div');
  line.setAttribute('id', String(cnt)+String(cnt));
  var elementAbovee = document.getElementById("update");
  // FINALLY ADD THE NEWLY CREATED TABLE AND BUTTON TO THE BODY.
        elementAbove.appendChild(button);
  elementAbovee.appendChild(line);
        setthing();
    }
  function setthing(){
  var div = document.getElementById(String(cnt)+String(cnt));
  div.innerHTML = div.innerHTML.replace('','Class '+cnt+' Samples:');
}

function crtlnk(){
      var link = document.createElement('a');
      link.setAttribute("href","#slide-"+cnt);
      body = document.getElementById("x");
      link.textContent=cnt;
      body.appendChild(link);
    }
function crtdiv(){
  var dive = document.createElement('div');
  dive.setAttribute("id","slide-"+cnt);
  aj=document.getElementById("z");
  aj.appendChild(dive);
}
function crtvid(){
  var dive = document.createElement('div');
  dive.setAttribute("id",cnt+"a");
  aj=document.getElementById("slide-"+cnt);
  aj.appendChild(dive);
  var vid = document.createElement('video');
  vid.setAttribute("class","my_class_name");
  vid.setAttribute("autoplay",String.Empty);
  vid.setAttribute("playsinline",String.Empty);
  vid.setAttribute("muted",String.Empty);
  vid.setAttribute("id",cnt+"cc");
  vid.setAttribute("width","224");
  vid.setAttribute("height","224");
  aj=document.getElementById(cnt+"a");
  aj.appendChild(vid);
}
function crtbr(){
  var br = document.createElement('br');
  aj=document.getElementById("slide-"+cnt);
  aj.appendChild(br);
}
function crtdvstl(){
  var dive = document.createElement('div');
  dive.style.display="block";
  dive.setAttribute("id",cnt+"b");
  aj=document.getElementById("slide-"+cnt);
  aj.appendChild(dive);
}
function crtbtn1(){
  var btn = document.createElement('button');
  btn.setAttribute("class","button");
  btn.setAttribute("id",cnt);
  btn.setAttribute("onclick","handleButton(this)");
  btn.textContent="Class "+cnt;
  aj=document.getElementById(cnt+"b");
  aj.appendChild(btn);
}

function crtbr1(){
  var br = document.createElement('br');
  aj=document.getElementById(cnt+"b");
  aj.appendChild(br);
}
function para(){
  var para = document.createElement('p');
  para.setAttribute("id",String(cnt)+String(cnt));
  para.textContent="Class "+cnt+" count: ";
  aj=document.getElementById(cnt+"b");
  aj.appendChild(para);
}
function crtbr2(){
  var br = document.createElement('br');
  aj=document.getElementById(cnt+"b");
  aj.appendChild(br);
}
function crtbtn2(){
  var btn = document.createElement('button');
  btn.setAttribute("class","button");
  btn.setAttribute("id",cnt+"t");
  btn.setAttribute("onclick","stpcm(this)");
  btn.textContent="Stop cam";
  aj=document.getElementById(cnt+"b");
  aj.appendChild(btn);
  var br = document.createElement('br');
  aj=document.getElementById(cnt+"b");
  aj.appendChild(br);
  var btn = document.createElement('button');
  btn.setAttribute("class","button");
  btn.setAttribute("id",cnt+"c");
  btn.setAttribute("onclick","strcm(this)");
  btn.textContent="Start cam";
  aj.appendChild(btn);
}

function crtcard(){
  cnt++;
  crtlnk();
  crtdiv();
  crtvid();
  crtbr();
  crtdvstl();
  crtbtn1();
  crtbr1();
  para();
  //crtbr2();
  crtbtn2();
}
function stpcm(elem){
  var video = document.getElementById("wc");

// A video's MediaStream object is available through its srcObject attribute
var mediaStream = video.srcObject;

// Through the MediaStream, you can get the MediaStreamTracks with getTracks():
var tracks = mediaStream.getTracks();

// Tracks are returned as an array, so if you know you only have one, you can stop it with: 
tracks.forEach(track => track.stop())
document.getElementById("wc").id=(elem.id).charAt(0)+"cc";
}
function strcm(elem)
{
  document.getElementById(elem.id+"c").id="wc";
  init();
}

function startPredicting1(elem){
  document.getElementById(elem.id+"c").id="wc";
  init1();
  startPredicting();
}

function stopPredicting1(elem){
  stopPredicting();
  stpcm(elem);
}
</script>
<style type="text/css">
  * {
  box-sizing: border-box;
}

#we{
  margin-left: 10px;
}

#we1{
  position: absolute;
  top: 510px; 
  left: 750px;
}

.slider {
  width: 420px;
  display: block;
  overflow: hidden;
}

.slides {
  display: flex;
  
  overflow-x: auto;
  scroll-snap-type: x mandatory;
  
  
  
  scroll-behavior: smooth;
  -webkit-overflow-scrolling: touch;
  
  /*
  scroll-snap-points-x: repeat(300px);
  scroll-snap-type: mandatory;
  */
}
.slides::-webkit-scrollbar {
  width: 10px;
  height: 10px;
}
.slides::-webkit-scrollbar-thumb {
  background: blue;
  border-radius: 10px;
}
.slides::-webkit-scrollbar-track {
  background: transparent;
}
.slides > div {
  scroll-snap-align: start;
  flex-shrink: 0;
  width: 400px;
  height: 400px;
  margin-right: 50px;
  border-radius: 10px;
  background: #add8e6;
  transform-origin: center center;
  transform: scale(1);
  transition: transform 0.5s;
  position: relative;
  
  display: inline-flex;
  align-items: center;
  justify-content: center;
  font-size: 20px;
}
.slides > div:target {
/*   transform: scale(0.8); */
}
.author-info {
  background: rgba(0, 0, 0, 0.75);
  color: white;
  padding: 0.75rem;
  text-align: center;
  position: absolute;
  bottom: 0;
  left: 0;
  width: 100%;
  margin: 0;
}
.author-info a {
  color: white;
}
img {
  object-fit: cover;
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
}

.slider > a {
  display: inline-flex;
  width: 1.5rem;
  height: 1.5rem;
  background: white;
  text-decoration: none;
  align-items: center;
  justify-content: center;
  border-radius: 50%;
  margin: 0 0 0.5rem 0;
  position: relative;
}
.slider > a:active {
  top: 1px;
}
.slider > a:focus {
  background: #000;
}

/* Don't need button navigation */
@supports (scroll-snap-type) {
  .slider > a {
    display: none;
  }
}



.button {
  display: block;
  padding: 8px 13px;
  font-size: 12px;
  text-align: center;
  cursor: pointer;
  outline: none;
  color: #fff;
  background-color: #4CAF50;
  border: none;
  border-radius: 15px;
  box-shadow: 0 9px #999;
}
.button:active {
  background-color: #3e8e41;
  box-shadow: 0 5px #666;
  transform: translateY(2px);
}
.my_class_name {
  margin: 0 auto;
  border: 10px outset #ddd;
  align-items: center;
}
</style>
  </head>

  <body>

    <header>
      
      <div class="navbar navbar-dark bg-dark box-shadow">
        <div class="container d-flex justify-content-between">
          <a href="/" class="navbar-brand d-flex align-items-center">
            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="mr-2"><path d="M23 19a2 2 0 0 1-2 2H3a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h4l2-3h6l2 3h4a2 2 0 0 1 2 2z"></path><circle cx="12" cy="13" r="4"></circle></svg>
            <strong>Computer Vision</strong>
          </a>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarHeader" aria-controls="navbarHeader" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
        </div>
      </div>
    </header>
    <section class="jumbotron text-center">
        <div class="container">
          <h1 class="jumbotron-heading">Train your Machine learning model right in your browser!</h1>
          <p class="lead text-black">
            <h3><b>Trainable Image Classifier</b></h3>
            <p>
          Hello! folks this is an in browser classifier which let you train your images and even download your trainred model. First of all you have to choose number of classes and then start cam followed by clicking the class button to click your sample images then stop the camera. Repeat the same for all the classes. Then click on Train button and you will be notified when training is complete.Then click on predict now for preparing the camera. Finally click on start predicting for real time prediction.</p></p>
          <p>
            <a href="https://github.com/manupatel007" class="btn btn-primary my-2">Follow me on GitHub</a>
            <a href="https://www.linkedin.com/in/vishwas-patel-136a3316b/" class="btn btn-secondary my-2">Linkedin</a>
          </p>
        </div>
      </section>
      <div class="slider">
<div id="we">
  <div id="x">
  <a href="#slide-0">0</a>
  <a href="#slide-1">1</a>
  </div>

  <div class="slides" id="z">
    <div id="slide-0">
    <div>
      <video class="my_class_name" autoplay playsinline muted id="0cc" width="224" height="224"></video>
    </div>
  <br>
  <div style="display: block;" id="0b">
  <button class="button" id="0" onclick="handleButton(this)" >Class 0</button>
  <br>
  <p id="00">Class 0 count:</p>
  <button class="button" id="0t" onclick="stpcm(this)">Stop cam</button>
  <br>
  <button class="button" id="0c" onclick="strcm(this)">start cam</button>
  </div>
  </div>
    <div id="slide-1">
    <div>
      <video class="my_class_name" autoplay playsinline muted id="1cc" width="224" height="224"></video>
    </div>
  <br>
  <div style="display: block;" id="1b">
  <button class="button" id="1" onclick="handleButton(this)" >Class 1</button>
  <br>
  <p id="11">Class 1 count:</p>
  <button class="button" id="1t" onclick="stpcm(this)" >Stop cam</button>
  <br>
  <button class="button" id="1c" onclick="strcm(this)">start cam</button>
  </div>
  </div>
</div>
<br>
  <button type="button" class="btn btn-primary" onclick="crtcard()">Add More Classes</button>
  <button type="button" class="btn btn-primary"
   id="train" onclick="doTraining()" >Train Network</button>
   <button type="button" class="btn btn-primary" onclick="init()">Predict Now</button>
  <div id="dummy">You will be notified when training is complete</div>
  </div>
<div id="we1">
  <p>Now let's start predicting</p>
  <div>
      <video class="my_class_name" autoplay playsinline muted id="wc" width="224" height="224"></video>
    </div>
    <button type="button" class="btn btn-primary" id="9c" onclick="startPredicting()" >Start Predicting</button>
    <button type="button" class="btn btn-primary" id="9t" onclick="stopPredicting()" >Stop Predicting</button>
    <br>
    <br>
    <button type="button" class="btn btn-primary" id="downloadmodel" onclick="dwnld()">Save model</button>
    <br>
    <div id="prediction"></div>
</div>
  </body>
  <script>
    let mobilenet;
let model;
var webcam = new Webcam(document.getElementById('wc'));
const dataset = new RPSDataset();
var maxm=0;
let isPredicting = false;

var arr = [0,0,0,0,0,0,0,0,0,0];

async function loadMobilenet() {
  const mobilenet = await tf.loadLayersModel('https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_0.25_224/model.json');
  const layer = mobilenet.getLayer('conv_pw_13_relu');
  return tf.model({inputs: mobilenet.inputs, outputs: layer.output});
}

async function train() {
  maxm++; //as training starts from zero
  dataset.ys = null;
  dataset.encodeLabels(maxm);
  model = tf.sequential({
    layers: [
      tf.layers.flatten({inputShape: mobilenet.outputs[0].shape.slice(1)}),
      tf.layers.dense({ units: 100, activation: 'relu'}),
      tf.layers.dense({ units: maxm, activation: 'softmax'})
    ]
  });
  const optimizer = tf.train.adam(0.0001);
  model.compile({optimizer: optimizer, loss: 'categoricalCrossentropy'});
  let loss = 0;
  model.fit(dataset.xs, dataset.ys, {
    epochs: 10,
    callbacks: {
      onBatchEnd: async (batch, logs) => {
        loss = logs.loss.toFixed(5);
        console.log('LOSS: ' + loss);
        }
      }
   });
  document.getElementById("dummy").innerText = "Training is complete!";
  window.alert("Training is complete!")
}


function handleButton(elem){
	arr[elem.id]++;
	document.getElementById(String(elem.id)+String(elem.id)).innerText = "Class "+elem.id+" Samples:" + arr[elem.id];
	label = parseInt(elem.id);
	const img = webcam.capture();
	dataset.addExample(mobilenet.predict(img), label);
	if(maxm<elem.id){
		maxm=elem.id;
	}
}

async function predict() {
  while (isPredicting) {
    const predictedClass = tf.tidy(() => {
      const img = webcam.capture();
      const activation = mobilenet.predict(img);
      const predictions = model.predict(activation);
      return predictions.as1D().argMax();
    });
    const classId = (await predictedClass.data())[0];
    var predictionText = "";
    predictionText="I see class " + classId;
	document.getElementById("prediction").innerText = predictionText;
			
    
    predictedClass.dispose();
    await tf.nextFrame();
  }
}


function doTraining(){
	train();
}

function startPredicting(){
	isPredicting = true;
	predict();
}

function stopPredicting(){
	isPredicting = false;
	predict();
}

async function init(){
	webcam = new Webcam(document.getElementById('wc'));
	await webcam.setup();
	mobilenet = await loadMobilenet();
	tf.tidy(() => mobilenet.predict(webcam.capture()));
		
}

async function init1(){
	webcam = new Webcam(document.getElementById('wc'));
	await webcam.setup();
	}

async function dwnld(){
	await model.save('downloads://my-model');
}


init();
  </script>
  </html>
